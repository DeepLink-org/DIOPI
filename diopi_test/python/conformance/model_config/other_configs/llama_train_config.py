from ...config import Genfunc
from ...diopi_runtime import Dtype

llama_train_config = {
    'normal_': dict(
        name=["normal_"],
        no_output_ref=True,
        para=dict(
            size=[(32000, 4096)],
            mean=[0.0],
            std=[1.0],
        ),
    ),

    'uniform': dict(
        name=["uniform"],
        no_output_ref=True,
        para=dict(
            start=[-0.015624999999999998, -0.015624999999999998, -0.009531160645787792, -0.015624999999999998],
            end=[0.015624999999999998, 0.015624999999999998, 0.009531160645787792, 0.015624999999999998],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(4096, 4096), (11008, 4096), (4096, 11008), (32000, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'arange': dict(
        name=["arange"],
        interface=["torch"],
        para=dict(
            start=[0],
            end=[128],
            step=[2],
        ),
    ),

    'div': dict(
        name=["div"],
        interface=["torch.Tensor"],
        para=dict(
            other=[128, 11.313708498984761, 1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(64,), (2, 32, 128, 128), ()],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'pow': dict(
        name=["pow"],
        interface=["torch.Tensor"],
        para=dict(
            exponent=[10000.0],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(64,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'pow_1': dict(
        name=["pow"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [()],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.positive,
                },
                {
                    "ins": ["exponent"],
                    "shape": [(64,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'div_1': dict(
        name=["div"],
        interface=["torch.Tensor"],
        para=dict(
            other=[1.0],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(64,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'reciprocal': dict(
        name=["reciprocal"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(64,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'mul': dict(
        name=["mul"],
        interface=["torch.Tensor"],
        para=dict(
            other=[1.0, -10000],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(64,), (128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'polar': dict(
        name=["polar"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["abs"],
                    "shape": [(4096, 64)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["angle"],
                    "shape": [(4096, 64)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'copy_': dict(
        name=["copy_"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["other"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float16],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'embedding': dict(
        name=["embedding"],
        para=dict(
            padding_idx=[None],
            max_norm=[None],
            norm_type=[2.0],
            scale_grad_by_freq=[False],
            sparse=[False],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128)],
                    "dtype": [Dtype.int64],
                    "gen_fn": Genfunc.randint,
                },
                {
                    "ins": ["weight"],
                    "requires_grad": [True],
                    "shape": [(32000, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'dropout': dict(
        name=["dropout"],
        no_output_ref=True,
        para=dict(
            p=[0.0, 0.0],
            training=[True, True],
            inplace=[False, False],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 4096), (2, 32, 128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'tril': dict(
        name=["tril"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'sub': dict(
        name=["sub"],
        interface=["torch.Tensor"],
        para=dict(
            other=[1.0],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'pow_2': dict(
        name=["pow"],
        interface=["torch.Tensor"],
        para=dict(
            exponent=[2],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'mean': dict(
        name=["mean"],
        interface=["torch.Tensor"],
        para=dict(
            dim=[-1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'add': dict(
        name=["add"],
        interface=["torch.Tensor"],
        para=dict(
            other=[1e-06],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 1)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'rsqrt': dict(
        name=["rsqrt"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 1)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.positive,
                },
            ],
        ),
    ),

    'mul_1': dict(
        name=["mul"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 4096), (2, 128, 4096), (2, 128, 11008)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["other"],
                    "shape": [(2, 128, 1), (4096,), (2, 128, 11008)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'linear': dict(
        name=["linear"],
        atol=1e-03,
        rtol=1e-04,
        atol_half=1e-01,
        rtol_half=1e-02,
        para=dict(
            bias=[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "requires_grad": [True],
                    "shape": [(2, 128, 4096), (2, 128, 4096), (2, 128, 11008), (152, 4096), (143, 4096), (142, 4096), (35, 4096), (146, 4096), (79, 4096), (94, 4096), (67, 4096), (256, 4096), (171, 4096), (136, 4096), (29, 4096), (156, 4096), (107, 4096), (60, 4096), (46, 4096), (56, 4096), (57, 4096), (144, 4096), (127, 4096), (81, 4096), (122, 4096), (63, 4096), (26, 4096), (170, 4096), (179, 4096), (124, 4096), (82, 4096), (19, 4096), (53, 4096), (145, 4096), (90, 4096), (155, 4096), (59, 4096), (115, 4096), (87, 4096), (113, 4096), (47, 4096), (199, 4096), (95, 4096), (130, 4096), (55, 4096), (111, 4096), (123, 4096), (31, 4096), (15, 4096), (137, 4096), (116, 4096), (33, 4096), (62, 4096), (85, 4096), (84, 4096), (160, 4096), (96, 4096), (80, 4096), (49, 4096), (183, 4096), (135, 4096), (178, 4096), (150, 4096), (73, 4096), (28, 4096), (39, 4096), (103, 4096), (64, 4096), (159, 4096), (188, 4096), (216, 4096), (151, 4096), (34, 4096), (32, 4096), (104, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["weight"],
                    "requires_grad": [True],
                    "shape": [(4096, 4096), (11008, 4096), (4096, 11008), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096), (32000, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'transpose': dict(
        name=["transpose"],
        interface=["torch.Tensor"],
        para=dict(
            dim0=[1, 1, -2],
            dim1=[2, 2, -1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 32, 128), (2, 32, 128, 128), (2, 32, 128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'view_as_complex': dict(
        name=["view_as_complex"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 32, 64, 2)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'mul_2': dict(
        name=["mul"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 32, 64)],
                    "dtype": [Dtype.complex64],
                    "gen_fn": Genfunc.randn_cmplx,
                },
                {
                    "ins": ["other"],
                    "shape": [(1, 128, 1, 64)],
                    "dtype": [Dtype.complex64],
                    "gen_fn": Genfunc.randn_cmplx,
                },
            ],
        ),
    ),

    'view_as_real': dict(
        name=["view_as_real"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 128, 32, 64)],
                    "dtype": [Dtype.complex64],
                    "gen_fn": Genfunc.randn_cmplx,
                },
            ],
        ),
    ),

    'matmul': dict(
        name=["matmul"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 32, 128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["other"],
                    "shape": [(2, 32, 128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'add_1': dict(
        name=["add"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 32, 128, 128), (2, 128, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["other"],
                    "shape": [(2, 1, 128, 128), (2, 128, 4096)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'softmax': dict(
        name=["softmax"],
        saved_args=dict(output=0),
        para=dict(
            dim=[-1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(2, 32, 128, 128)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'gt': dict(
        name=["gt"],
        interface=["torch.Tensor"],
        para=dict(
            other=[0],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(256,)],
                    "dtype": [Dtype.int64],
                    "gen_fn": Genfunc.randint,
                },
            ],
        ),
    ),

    'log_softmax': dict(
        name=["log_softmax"],
        saved_args=dict(output=0),
        para=dict(
            dim=[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(152, 32000), (143, 32000), (142, 32000), (35, 32000), (146, 32000), (79, 32000), (94, 32000), (67, 32000), (256, 32000), (171, 32000), (136, 32000), (29, 32000), (156, 32000), (107, 32000), (60, 32000), (46, 32000), (56, 32000), (57, 32000), (144, 32000), (127, 32000), (81, 32000), (122, 32000), (63, 32000), (26, 32000), (170, 32000), (179, 32000), (124, 32000), (82, 32000), (19, 32000), (53, 32000), (145, 32000), (90, 32000), (155, 32000), (59, 32000), (115, 32000), (87, 32000), (113, 32000), (47, 32000), (199, 32000), (95, 32000), (130, 32000), (55, 32000), (111, 32000), (123, 32000), (31, 32000), (15, 32000), (137, 32000), (116, 32000), (33, 32000), (62, 32000), (85, 32000), (84, 32000), (160, 32000), (96, 32000), (80, 32000), (49, 32000), (183, 32000), (135, 32000), (178, 32000), (150, 32000), (73, 32000), (28, 32000), (39, 32000), (103, 32000), (64, 32000), (159, 32000), (188, 32000), (216, 32000), (151, 32000), (34, 32000), (32, 32000), (104, 32000)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'argmax': dict(
        name=["argmax"],
        interface=["torch.Tensor"],
        para=dict(
            dim=[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(152, 32000), (143, 32000), (142, 32000), (35, 32000), (146, 32000), (79, 32000), (94, 32000), (67, 32000), (256, 32000), (171, 32000), (136, 32000), (29, 32000), (156, 32000), (107, 32000), (60, 32000), (46, 32000), (56, 32000), (57, 32000), (144, 32000), (127, 32000), (81, 32000), (122, 32000), (63, 32000), (26, 32000), (170, 32000), (179, 32000), (124, 32000), (82, 32000), (19, 32000), (53, 32000), (145, 32000), (90, 32000), (155, 32000), (59, 32000), (115, 32000), (87, 32000), (113, 32000), (47, 32000), (199, 32000), (95, 32000), (130, 32000), (55, 32000), (111, 32000), (123, 32000), (31, 32000), (15, 32000), (137, 32000), (116, 32000), (33, 32000), (62, 32000), (85, 32000), (84, 32000), (160, 32000), (96, 32000), (80, 32000), (49, 32000), (183, 32000), (135, 32000), (178, 32000), (150, 32000), (73, 32000), (28, 32000), (39, 32000), (103, 32000), (64, 32000), (159, 32000), (188, 32000), (216, 32000), (151, 32000), (34, 32000), (32, 32000), (104, 32000)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'eq': dict(
        name=["eq"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(152,), (143,), (142,), (35,), (146,), (79,), (94,), (67,), (256,), (171,), (136,), (29,), (156,), (107,), (60,), (46,), (56,), (57,), (144,), (127,), (81,), (122,), (63,), (26,), (170,), (179,), (124,), (82,), (19,), (53,), (145,), (90,), (155,), (59,), (115,), (87,), (113,), (47,), (199,), (95,), (130,), (55,), (111,), (123,), (31,), (15,), (137,), (116,), (33,), (62,), (85,), (84,), (160,), (96,), (80,), (49,), (183,), (135,), (178,), (150,), (73,), (28,), (39,), (103,), (64,), (159,), (188,), (216,), (151,), (34,), (32,), (104,)],
                    "dtype": [Dtype.int64],
                    "gen_fn": Genfunc.randint,
                },
                {
                    "ins": ["other"],
                    "shape": [(152,), (143,), (142,), (35,), (146,), (79,), (94,), (67,), (256,), (171,), (136,), (29,), (156,), (107,), (60,), (46,), (56,), (57,), (144,), (127,), (81,), (122,), (63,), (26,), (170,), (179,), (124,), (82,), (19,), (53,), (145,), (90,), (155,), (59,), (115,), (87,), (113,), (47,), (199,), (95,), (130,), (55,), (111,), (123,), (31,), (15,), (137,), (116,), (33,), (62,), (85,), (84,), (160,), (96,), (80,), (49,), (183,), (135,), (178,), (150,), (73,), (28,), (39,), (103,), (64,), (159,), (188,), (216,), (151,), (34,), (32,), (104,)],
                    "dtype": [Dtype.int64],
                    "gen_fn": Genfunc.randint,
                },
            ],
        ),
    ),

    'sum': dict(
        name=["sum"],
        interface=["torch"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(152,), (143,), (142,), (35,), (146,), (79,), (94,), (67,), (256,), (171,), (136,), (29,), (156,), (107,), (60,), (46,), (56,), (57,), (144,), (127,), (81,), (122,), (63,), (26,), (170,), (179,), (124,), (82,), (19,), (53,), (145,), (90,), (155,), (59,), (115,), (87,), (113,), (47,), (199,), (95,), (130,), (55,), (111,), (123,), (31,), (15,), (137,), (116,), (33,), (62,), (85,), (84,), (160,), (96,), (80,), (49,), (183,), (135,), (178,), (150,), (73,), (28,), (39,), (103,), (64,), (159,), (188,), (216,), (151,), (34,), (32,), (104,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'nll_loss': dict(
        name=["nll_loss"],
        para=dict(
            reduction=['mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean', 'mean'],
            ignore_index=[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(152, 32000), (143, 32000), (142, 32000), (35, 32000), (146, 32000), (79, 32000), (94, 32000), (67, 32000), (256, 32000), (171, 32000), (136, 32000), (29, 32000), (156, 32000), (107, 32000), (60, 32000), (46, 32000), (56, 32000), (57, 32000), (144, 32000), (127, 32000), (81, 32000), (122, 32000), (63, 32000), (26, 32000), (170, 32000), (179, 32000), (124, 32000), (82, 32000), (19, 32000), (53, 32000), (145, 32000), (90, 32000), (155, 32000), (59, 32000), (115, 32000), (87, 32000), (113, 32000), (47, 32000), (199, 32000), (95, 32000), (130, 32000), (55, 32000), (111, 32000), (123, 32000), (31, 32000), (15, 32000), (137, 32000), (116, 32000), (33, 32000), (62, 32000), (85, 32000), (84, 32000), (160, 32000), (96, 32000), (80, 32000), (49, 32000), (183, 32000), (135, 32000), (178, 32000), (150, 32000), (73, 32000), (28, 32000), (39, 32000), (103, 32000), (64, 32000), (159, 32000), (188, 32000), (216, 32000), (151, 32000), (34, 32000), (32, 32000), (104, 32000)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["target"],
                    "shape": [(152,), (143,), (142,), (35,), (146,), (79,), (94,), (67,), (256,), (171,), (136,), (29,), (156,), (107,), (60,), (46,), (56,), (57,), (144,), (127,), (81,), (122,), (63,), (26,), (170,), (179,), (124,), (82,), (19,), (53,), (145,), (90,), (155,), (59,), (115,), (87,), (113,), (47,), (199,), (95,), (130,), (55,), (111,), (123,), (31,), (15,), (137,), (116,), (33,), (62,), (85,), (84,), (160,), (96,), (80,), (49,), (183,), (135,), (178,), (150,), (73,), (28,), (39,), (103,), (64,), (159,), (188,), (216,), (151,), (34,), (32,), (104,)],
                    "dtype": [Dtype.int64],
                    "gen_fn": Genfunc.randint,
                },
            ],
        ),
    ),

    'mul_3': dict(
        name=["mul"],
        is_inplace=[True],
        interface=["torch.Tensor"],
        para=dict(
            other=[0.9, 0.999, 0.9, 0.999, 0.9, 0.999, 0.9, 0.999, 0.9, 0.999],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (32000, 4096), (4096, 4096), (4096, 4096), (11008, 4096), (11008, 4096), (4096, 11008), (4096, 11008), (4096,), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'add_2': dict(
        name=["add"],
        interface=["torch.Tensor"],
        para=dict(
            alpha=[0.09999999999999998, -0.0, 0.09999999999999998, -0.0, 0.09999999999999998, -0.0, 0.09999999999999998, -0.0, 0.09999999999999998, -0.0, -1.0000000000000001e-07, -1.0000000000000001e-07, -1.0000000000000001e-07, -1.0000000000000001e-07, -1.0000000000000001e-07, -2.0000000000000002e-07, -2.0000000000000002e-07, -2.0000000000000002e-07, -2.0000000000000002e-07, -2.0000000000000002e-07, -3.0000000000000004e-07, -3.0000000000000004e-07, -3.0000000000000004e-07, -3.0000000000000004e-07, -3.0000000000000004e-07, -4.0000000000000003e-07, -4.0000000000000003e-07, -4.0000000000000003e-07, -4.0000000000000003e-07, -4.0000000000000003e-07, -5.000000000000001e-07, -5.000000000000001e-07, -5.000000000000001e-07, -5.000000000000001e-07, -5.000000000000001e-07, -6.000000000000001e-07, -6.000000000000001e-07, -6.000000000000001e-07, -6.000000000000001e-07, -6.000000000000001e-07, -7e-07, -7e-07, -7e-07, -7e-07, -7e-07, -8.000000000000001e-07, -8.000000000000001e-07, -8.000000000000001e-07, -8.000000000000001e-07, -8.000000000000001e-07, -9.000000000000001e-07, -9.000000000000001e-07, -9.000000000000001e-07, -9.000000000000001e-07, -9.000000000000001e-07, -1.0000000000000002e-06, -1.0000000000000002e-06, -1.0000000000000002e-06, -1.0000000000000002e-06, -1.0000000000000002e-06, -9.88888888888889e-07, -9.88888888888889e-07, -9.88888888888889e-07, -9.88888888888889e-07, -9.88888888888889e-07, -9.777777777777778e-07, -9.777777777777778e-07, -9.777777777777778e-07, -9.777777777777778e-07, -9.777777777777778e-07, -9.666666666666666e-07, -9.666666666666666e-07, -9.666666666666666e-07, -9.666666666666666e-07, -9.666666666666666e-07, -9.555555555555556e-07, -9.555555555555556e-07, -9.555555555555556e-07, -9.555555555555556e-07, -9.555555555555556e-07, -9.444444444444444e-07, -9.444444444444444e-07, -9.444444444444444e-07, -9.444444444444444e-07, -9.444444444444444e-07, -9.333333333333334e-07, -9.333333333333334e-07, -9.333333333333334e-07, -9.333333333333334e-07, -9.333333333333334e-07, -9.222222222222223e-07, -9.222222222222223e-07, -9.222222222222223e-07, -9.222222222222223e-07, -9.222222222222223e-07, -9.111111111111112e-07, -9.111111111111112e-07, -9.111111111111112e-07, -9.111111111111112e-07, -9.111111111111112e-07, -8.88888888888889e-07, -8.88888888888889e-07, -8.88888888888889e-07, -8.88888888888889e-07, -8.88888888888889e-07, -8.777777777777778e-07, -8.777777777777778e-07, -8.777777777777778e-07, -8.777777777777778e-07, -8.777777777777778e-07, -8.666666666666667e-07, -8.666666666666667e-07, -8.666666666666667e-07, -8.666666666666667e-07, -8.666666666666667e-07, -8.555555555555556e-07, -8.555555555555556e-07, -8.555555555555556e-07, -8.555555555555556e-07, -8.555555555555556e-07, -8.444444444444444e-07, -8.444444444444444e-07, -8.444444444444444e-07, -8.444444444444444e-07, -8.444444444444444e-07, -8.333333333333334e-07, -8.333333333333334e-07, -8.333333333333334e-07, -8.333333333333334e-07, -8.333333333333334e-07, -8.222222222222222e-07, -8.222222222222222e-07, -8.222222222222222e-07, -8.222222222222222e-07, -8.222222222222222e-07, -8.111111111111112e-07, -8.111111111111112e-07, -8.111111111111112e-07, -8.111111111111112e-07, -8.111111111111112e-07, -7.88888888888889e-07, -7.88888888888889e-07, -7.88888888888889e-07, -7.88888888888889e-07, -7.88888888888889e-07, -7.777777777777778e-07, -7.777777777777778e-07, -7.777777777777778e-07, -7.777777777777778e-07, -7.777777777777778e-07, -7.666666666666667e-07, -7.666666666666667e-07, -7.666666666666667e-07, -7.666666666666667e-07, -7.666666666666667e-07, -7.555555555555556e-07, -7.555555555555556e-07, -7.555555555555556e-07, -7.555555555555556e-07, -7.555555555555556e-07, -7.444444444444444e-07, -7.444444444444444e-07, -7.444444444444444e-07, -7.444444444444444e-07, -7.444444444444444e-07, -7.333333333333333e-07, -7.333333333333333e-07, -7.333333333333333e-07, -7.333333333333333e-07, -7.333333333333333e-07, -7.222222222222222e-07, -7.222222222222222e-07, -7.222222222222222e-07, -7.222222222222222e-07, -7.222222222222222e-07, -7.111111111111112e-07, -7.111111111111112e-07, -7.111111111111112e-07, -7.111111111111112e-07, -7.111111111111112e-07, -6.88888888888889e-07, -6.88888888888889e-07, -6.88888888888889e-07, -6.88888888888889e-07, -6.88888888888889e-07, -6.777777777777778e-07, -6.777777777777778e-07, -6.777777777777778e-07, -6.777777777777778e-07, -6.777777777777778e-07, -6.666666666666667e-07, -6.666666666666667e-07, -6.666666666666667e-07, -6.666666666666667e-07, -6.666666666666667e-07, -6.555555555555556e-07, -6.555555555555556e-07, -6.555555555555556e-07, -6.555555555555556e-07, -6.555555555555556e-07, -6.444444444444446e-07, -6.444444444444446e-07, -6.444444444444446e-07, -6.444444444444446e-07, -6.444444444444446e-07, -6.333333333333333e-07, -6.333333333333333e-07, -6.333333333333333e-07, -6.333333333333333e-07, -6.333333333333333e-07, -6.222222222222223e-07, -6.222222222222223e-07, -6.222222222222223e-07, -6.222222222222223e-07, -6.222222222222223e-07, -6.111111111111113e-07, -6.111111111111113e-07, -6.111111111111113e-07, -6.111111111111113e-07, -6.111111111111113e-07, -5.88888888888889e-07, -5.88888888888889e-07, -5.88888888888889e-07, -5.88888888888889e-07, -5.88888888888889e-07, -5.777777777777778e-07, -5.777777777777778e-07, -5.777777777777778e-07, -5.777777777777778e-07, -5.777777777777778e-07, -5.666666666666667e-07, -5.666666666666667e-07, -5.666666666666667e-07, -5.666666666666667e-07, -5.666666666666667e-07, -5.555555555555556e-07, -5.555555555555556e-07, -5.555555555555556e-07, -5.555555555555556e-07, -5.555555555555556e-07, -5.444444444444444e-07, -5.444444444444444e-07, -5.444444444444444e-07, -5.444444444444444e-07, -5.444444444444444e-07, -5.333333333333333e-07, -5.333333333333333e-07, -5.333333333333333e-07, -5.333333333333333e-07, -5.333333333333333e-07, -5.222222222222223e-07, -5.222222222222223e-07, -5.222222222222223e-07, -5.222222222222223e-07, -5.222222222222223e-07, -5.111111111111111e-07, -5.111111111111111e-07, -5.111111111111111e-07, -5.111111111111111e-07, -5.111111111111111e-07, -4.888888888888889e-07, -4.888888888888889e-07, -4.888888888888889e-07, -4.888888888888889e-07, -4.888888888888889e-07, -4.777777777777778e-07, -4.777777777777778e-07, -4.777777777777778e-07, -4.777777777777778e-07, -4.777777777777778e-07, -4.666666666666667e-07, -4.666666666666667e-07, -4.666666666666667e-07, -4.666666666666667e-07, -4.666666666666667e-07, -4.555555555555556e-07, -4.555555555555556e-07, -4.555555555555556e-07, -4.555555555555556e-07, -4.555555555555556e-07, -4.444444444444445e-07, -4.444444444444445e-07, -4.444444444444445e-07, -4.444444444444445e-07, -4.444444444444445e-07, -4.3333333333333335e-07, -4.3333333333333335e-07, -4.3333333333333335e-07, -4.3333333333333335e-07, -4.3333333333333335e-07, -4.222222222222222e-07, -4.222222222222222e-07, -4.222222222222222e-07, -4.222222222222222e-07, -4.222222222222222e-07, -4.111111111111111e-07, -4.111111111111111e-07, -4.111111111111111e-07, -4.111111111111111e-07, -4.111111111111111e-07, -3.888888888888889e-07, -3.888888888888889e-07, -3.888888888888889e-07, -3.888888888888889e-07, -3.888888888888889e-07, -3.777777777777778e-07, -3.777777777777778e-07, -3.777777777777778e-07, -3.777777777777778e-07, -3.777777777777778e-07, -3.6666666666666667e-07, -3.6666666666666667e-07, -3.6666666666666667e-07, -3.6666666666666667e-07, -3.6666666666666667e-07, -3.555555555555556e-07, -3.555555555555556e-07, -3.555555555555556e-07, -3.555555555555556e-07, -3.555555555555556e-07, -3.444444444444445e-07, -3.444444444444445e-07, -3.444444444444445e-07, -3.444444444444445e-07, -3.444444444444445e-07, -3.3333333333333335e-07, -3.3333333333333335e-07, -3.3333333333333335e-07, -3.3333333333333335e-07, -3.3333333333333335e-07, -3.222222222222223e-07, -3.222222222222223e-07, -3.222222222222223e-07, -3.222222222222223e-07, -3.222222222222223e-07, -3.111111111111111e-07, -3.111111111111111e-07, -3.111111111111111e-07, -3.111111111111111e-07, -3.111111111111111e-07, -2.888888888888889e-07, -2.888888888888889e-07, -2.888888888888889e-07, -2.888888888888889e-07, -2.888888888888889e-07, -2.777777777777778e-07, -2.777777777777778e-07, -2.777777777777778e-07, -2.777777777777778e-07, -2.777777777777778e-07, -2.6666666666666667e-07, -2.6666666666666667e-07, -2.6666666666666667e-07, -2.6666666666666667e-07, -2.6666666666666667e-07, -2.5555555555555553e-07, -2.5555555555555553e-07, -2.5555555555555553e-07, -2.5555555555555553e-07, -2.5555555555555553e-07, -2.4444444444444445e-07, -2.4444444444444445e-07, -2.4444444444444445e-07, -2.4444444444444445e-07, -2.4444444444444445e-07, -2.3333333333333336e-07, -2.3333333333333336e-07, -2.3333333333333336e-07, -2.3333333333333336e-07, -2.3333333333333336e-07, -2.2222222222222224e-07, -2.2222222222222224e-07, -2.2222222222222224e-07, -2.2222222222222224e-07, -2.2222222222222224e-07, -2.111111111111111e-07, -2.111111111111111e-07, -2.111111111111111e-07, -2.111111111111111e-07, -2.111111111111111e-07, -1.888888888888889e-07, -1.888888888888889e-07, -1.888888888888889e-07, -1.888888888888889e-07, -1.888888888888889e-07, -1.777777777777778e-07, -1.777777777777778e-07, -1.777777777777778e-07, -1.777777777777778e-07, -1.777777777777778e-07, -1.6666666666666668e-07, -1.6666666666666668e-07, -1.6666666666666668e-07, -1.6666666666666668e-07, -1.6666666666666668e-07, -1.5555555555555556e-07, -1.5555555555555556e-07, -1.5555555555555556e-07, -1.5555555555555556e-07, -1.5555555555555556e-07, -1.4444444444444445e-07, -1.4444444444444445e-07, -1.4444444444444445e-07, -1.4444444444444445e-07, -1.4444444444444445e-07, -1.3333333333333334e-07, -1.3333333333333334e-07, -1.3333333333333334e-07, -1.3333333333333334e-07, -1.3333333333333334e-07, -1.2222222222222222e-07, -1.2222222222222222e-07, -1.2222222222222222e-07, -1.2222222222222222e-07, -1.2222222222222222e-07, -1.1111111111111112e-07, -1.1111111111111112e-07, -1.1111111111111112e-07, -1.1111111111111112e-07, -1.1111111111111112e-07, -8.88888888888889e-08, -8.88888888888889e-08, -8.88888888888889e-08, -8.88888888888889e-08, -8.88888888888889e-08, -7.777777777777778e-08, -7.777777777777778e-08, -7.777777777777778e-08, -7.777777777777778e-08, -7.777777777777778e-08, -6.666666666666667e-08, -6.666666666666667e-08, -6.666666666666667e-08, -6.666666666666667e-08, -6.666666666666667e-08, -5.555555555555556e-08, -5.555555555555556e-08, -5.555555555555556e-08, -5.555555555555556e-08, -5.555555555555556e-08, -4.444444444444445e-08, -4.444444444444445e-08, -4.444444444444445e-08, -4.444444444444445e-08, -4.444444444444445e-08, -3.3333333333333334e-08, -3.3333333333333334e-08, -3.3333333333333334e-08, -3.3333333333333334e-08, -3.3333333333333334e-08, -2.2222222222222224e-08, -2.2222222222222224e-08, -2.2222222222222224e-08, -2.2222222222222224e-08, -2.2222222222222224e-08, -1.1111111111111112e-08, -1.1111111111111112e-08, -1.1111111111111112e-08, -1.1111111111111112e-08, -1.1111111111111112e-08],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (32000, 4096), (4096, 4096), (4096, 4096), (11008, 4096), (11008, 4096), (4096, 11008), (4096, 11008), (4096,), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["other"],
                    "shape": [(32000, 4096), (32000, 4096), (4096, 4096), (4096, 4096), (11008, 4096), (11008, 4096), (4096, 11008), (4096, 11008), (4096,), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'addcmul': dict(
        name=["addcmul"],
        interface=["torch.Tensor"],
        para=dict(
            value=[0.0010000000000000009, 0.0010000000000000009, 0.0010000000000000009, 0.0010000000000000009, 0.0010000000000000009],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["tensor1"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["tensor2"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'sqrt': dict(
        name=["sqrt"],
        interface=["torch.Tensor"],
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.positive,
                },
            ],
        ),
    ),

    'add_3': dict(
        name=["add"],
        interface=["torch.Tensor"],
        para=dict(
            other=[1e-06, 1e-06, 1e-06, 1e-06, 1e-06],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

    'addcdiv': dict(
        name=["addcdiv"],
        interface=["torch.Tensor"],
        para=dict(
            value=[-0.0, -0.0, -0.0, -0.0, -0.0, -1e-05, -1e-05, -1e-05, -1e-05, -1e-05, -2e-05, -2e-05, -2e-05, -2e-05, -2e-05, -3e-05, -3e-05, -3e-05, -3e-05, -3e-05, -4e-05, -4e-05, -4e-05, -4e-05, -4e-05, -5e-05, -5e-05, -5e-05, -5e-05, -5e-05, -6e-05, -6e-05, -6e-05, -6e-05, -6e-05, -7e-05, -7e-05, -7e-05, -7e-05, -7e-05, -8e-05, -8e-05, -8e-05, -8e-05, -8e-05, -9e-05, -9e-05, -9e-05, -9e-05, -9e-05, -0.0001, -0.0001, -0.0001, -0.0001, -0.0001, -9.888888888888889e-05, -9.888888888888889e-05, -9.888888888888889e-05, -9.888888888888889e-05, -9.888888888888889e-05, -9.777777777777778e-05, -9.777777777777778e-05, -9.777777777777778e-05, -9.777777777777778e-05, -9.777777777777778e-05, -9.666666666666667e-05, -9.666666666666667e-05, -9.666666666666667e-05, -9.666666666666667e-05, -9.666666666666667e-05, -9.555555555555557e-05, -9.555555555555557e-05, -9.555555555555557e-05, -9.555555555555557e-05, -9.555555555555557e-05, -9.444444444444444e-05, -9.444444444444444e-05, -9.444444444444444e-05, -9.444444444444444e-05, -9.444444444444444e-05, -9.333333333333334e-05, -9.333333333333334e-05, -9.333333333333334e-05, -9.333333333333334e-05, -9.333333333333334e-05, -9.222222222222223e-05, -9.222222222222223e-05, -9.222222222222223e-05, -9.222222222222223e-05, -9.222222222222223e-05, -9.111111111111112e-05, -9.111111111111112e-05, -9.111111111111112e-05, -9.111111111111112e-05, -9.111111111111112e-05, -8.888888888888889e-05, -8.888888888888889e-05, -8.888888888888889e-05, -8.888888888888889e-05, -8.888888888888889e-05, -8.777777777777778e-05, -8.777777777777778e-05, -8.777777777777778e-05, -8.777777777777778e-05, -8.777777777777778e-05, -8.666666666666667e-05, -8.666666666666667e-05, -8.666666666666667e-05, -8.666666666666667e-05, -8.666666666666667e-05, -8.555555555555556e-05, -8.555555555555556e-05, -8.555555555555556e-05, -8.555555555555556e-05, -8.555555555555556e-05, -8.444444444444444e-05, -8.444444444444444e-05, -8.444444444444444e-05, -8.444444444444444e-05, -8.444444444444444e-05, -8.333333333333334e-05, -8.333333333333334e-05, -8.333333333333334e-05, -8.333333333333334e-05, -8.333333333333334e-05, -8.222222222222222e-05, -8.222222222222222e-05, -8.222222222222222e-05, -8.222222222222222e-05, -8.222222222222222e-05, -8.111111111111112e-05, -8.111111111111112e-05, -8.111111111111112e-05, -8.111111111111112e-05, -8.111111111111112e-05, -7.88888888888889e-05, -7.88888888888889e-05, -7.88888888888889e-05, -7.88888888888889e-05, -7.88888888888889e-05, -7.777777777777778e-05, -7.777777777777778e-05, -7.777777777777778e-05, -7.777777777777778e-05, -7.777777777777778e-05, -7.666666666666667e-05, -7.666666666666667e-05, -7.666666666666667e-05, -7.666666666666667e-05, -7.666666666666667e-05, -7.555555555555556e-05, -7.555555555555556e-05, -7.555555555555556e-05, -7.555555555555556e-05, -7.555555555555556e-05, -7.444444444444444e-05, -7.444444444444444e-05, -7.444444444444444e-05, -7.444444444444444e-05, -7.444444444444444e-05, -7.333333333333333e-05, -7.333333333333333e-05, -7.333333333333333e-05, -7.333333333333333e-05, -7.333333333333333e-05, -7.222222222222222e-05, -7.222222222222222e-05, -7.222222222222222e-05, -7.222222222222222e-05, -7.222222222222222e-05, -7.111111111111112e-05, -7.111111111111112e-05, -7.111111111111112e-05, -7.111111111111112e-05, -7.111111111111112e-05, -6.88888888888889e-05, -6.88888888888889e-05, -6.88888888888889e-05, -6.88888888888889e-05, -6.88888888888889e-05, -6.777777777777778e-05, -6.777777777777778e-05, -6.777777777777778e-05, -6.777777777777778e-05, -6.777777777777778e-05, -6.666666666666667e-05, -6.666666666666667e-05, -6.666666666666667e-05, -6.666666666666667e-05, -6.666666666666667e-05, -6.555555555555556e-05, -6.555555555555556e-05, -6.555555555555556e-05, -6.555555555555556e-05, -6.555555555555556e-05, -6.444444444444446e-05, -6.444444444444446e-05, -6.444444444444446e-05, -6.444444444444446e-05, -6.444444444444446e-05, -6.333333333333333e-05, -6.333333333333333e-05, -6.333333333333333e-05, -6.333333333333333e-05, -6.333333333333333e-05, -6.222222222222222e-05, -6.222222222222222e-05, -6.222222222222222e-05, -6.222222222222222e-05, -6.222222222222222e-05, -6.111111111111112e-05, -6.111111111111112e-05, -6.111111111111112e-05, -6.111111111111112e-05, -6.111111111111112e-05, -5.8888888888888896e-05, -5.8888888888888896e-05, -5.8888888888888896e-05, -5.8888888888888896e-05, -5.8888888888888896e-05, -5.7777777777777776e-05, -5.7777777777777776e-05, -5.7777777777777776e-05, -5.7777777777777776e-05, -5.7777777777777776e-05, -5.666666666666667e-05, -5.666666666666667e-05, -5.666666666666667e-05, -5.666666666666667e-05, -5.666666666666667e-05, -5.555555555555556e-05, -5.555555555555556e-05, -5.555555555555556e-05, -5.555555555555556e-05, -5.555555555555556e-05, -5.4444444444444446e-05, -5.4444444444444446e-05, -5.4444444444444446e-05, -5.4444444444444446e-05, -5.4444444444444446e-05, -5.333333333333333e-05, -5.333333333333333e-05, -5.333333333333333e-05, -5.333333333333333e-05, -5.333333333333333e-05, -5.222222222222223e-05, -5.222222222222223e-05, -5.222222222222223e-05, -5.222222222222223e-05, -5.222222222222223e-05, -5.111111111111111e-05, -5.111111111111111e-05, -5.111111111111111e-05, -5.111111111111111e-05, -5.111111111111111e-05, -4.888888888888889e-05, -4.888888888888889e-05, -4.888888888888889e-05, -4.888888888888889e-05, -4.888888888888889e-05, -4.7777777777777784e-05, -4.7777777777777784e-05, -4.7777777777777784e-05, -4.7777777777777784e-05, -4.7777777777777784e-05, -4.666666666666667e-05, -4.666666666666667e-05, -4.666666666666667e-05, -4.666666666666667e-05, -4.666666666666667e-05, -4.555555555555556e-05, -4.555555555555556e-05, -4.555555555555556e-05, -4.555555555555556e-05, -4.555555555555556e-05, -4.4444444444444447e-05, -4.4444444444444447e-05, -4.4444444444444447e-05, -4.4444444444444447e-05, -4.4444444444444447e-05, -4.3333333333333334e-05, -4.3333333333333334e-05, -4.3333333333333334e-05, -4.3333333333333334e-05, -4.3333333333333334e-05, -4.222222222222222e-05, -4.222222222222222e-05, -4.222222222222222e-05, -4.222222222222222e-05, -4.222222222222222e-05, -4.111111111111111e-05, -4.111111111111111e-05, -4.111111111111111e-05, -4.111111111111111e-05, -4.111111111111111e-05, -3.888888888888889e-05, -3.888888888888889e-05, -3.888888888888889e-05, -3.888888888888889e-05, -3.888888888888889e-05, -3.777777777777778e-05, -3.777777777777778e-05, -3.777777777777778e-05, -3.777777777777778e-05, -3.777777777777778e-05, -3.6666666666666666e-05, -3.6666666666666666e-05, -3.6666666666666666e-05, -3.6666666666666666e-05, -3.6666666666666666e-05, -3.555555555555556e-05, -3.555555555555556e-05, -3.555555555555556e-05, -3.555555555555556e-05, -3.555555555555556e-05, -3.444444444444445e-05, -3.444444444444445e-05, -3.444444444444445e-05, -3.444444444444445e-05, -3.444444444444445e-05, -3.3333333333333335e-05, -3.3333333333333335e-05, -3.3333333333333335e-05, -3.3333333333333335e-05, -3.3333333333333335e-05, -3.222222222222223e-05, -3.222222222222223e-05, -3.222222222222223e-05, -3.222222222222223e-05, -3.222222222222223e-05, -3.111111111111111e-05, -3.111111111111111e-05, -3.111111111111111e-05, -3.111111111111111e-05, -3.111111111111111e-05, -2.8888888888888888e-05, -2.8888888888888888e-05, -2.8888888888888888e-05, -2.8888888888888888e-05, -2.8888888888888888e-05, -2.777777777777778e-05, -2.777777777777778e-05, -2.777777777777778e-05, -2.777777777777778e-05, -2.777777777777778e-05, -2.6666666666666667e-05, -2.6666666666666667e-05, -2.6666666666666667e-05, -2.6666666666666667e-05, -2.6666666666666667e-05, -2.5555555555555554e-05, -2.5555555555555554e-05, -2.5555555555555554e-05, -2.5555555555555554e-05, -2.5555555555555554e-05, -2.4444444444444445e-05, -2.4444444444444445e-05, -2.4444444444444445e-05, -2.4444444444444445e-05, -2.4444444444444445e-05, -2.3333333333333336e-05, -2.3333333333333336e-05, -2.3333333333333336e-05, -2.3333333333333336e-05, -2.3333333333333336e-05, -2.2222222222222223e-05, -2.2222222222222223e-05, -2.2222222222222223e-05, -2.2222222222222223e-05, -2.2222222222222223e-05, -2.111111111111111e-05, -2.111111111111111e-05, -2.111111111111111e-05, -2.111111111111111e-05, -2.111111111111111e-05, -1.888888888888889e-05, -1.888888888888889e-05, -1.888888888888889e-05, -1.888888888888889e-05, -1.888888888888889e-05, -1.777777777777778e-05, -1.777777777777778e-05, -1.777777777777778e-05, -1.777777777777778e-05, -1.777777777777778e-05, -1.6666666666666667e-05, -1.6666666666666667e-05, -1.6666666666666667e-05, -1.6666666666666667e-05, -1.6666666666666667e-05, -1.5555555555555555e-05, -1.5555555555555555e-05, -1.5555555555555555e-05, -1.5555555555555555e-05, -1.5555555555555555e-05, -1.4444444444444444e-05, -1.4444444444444444e-05, -1.4444444444444444e-05, -1.4444444444444444e-05, -1.4444444444444444e-05, -1.3333333333333333e-05, -1.3333333333333333e-05, -1.3333333333333333e-05, -1.3333333333333333e-05, -1.3333333333333333e-05, -1.2222222222222222e-05, -1.2222222222222222e-05, -1.2222222222222222e-05, -1.2222222222222222e-05, -1.2222222222222222e-05, -1.1111111111111112e-05, -1.1111111111111112e-05, -1.1111111111111112e-05, -1.1111111111111112e-05, -1.1111111111111112e-05, -8.88888888888889e-06, -8.88888888888889e-06, -8.88888888888889e-06, -8.88888888888889e-06, -8.88888888888889e-06, -7.777777777777777e-06, -7.777777777777777e-06, -7.777777777777777e-06, -7.777777777777777e-06, -7.777777777777777e-06, -6.666666666666667e-06, -6.666666666666667e-06, -6.666666666666667e-06, -6.666666666666667e-06, -6.666666666666667e-06, -5.555555555555556e-06, -5.555555555555556e-06, -5.555555555555556e-06, -5.555555555555556e-06, -5.555555555555556e-06, -4.444444444444445e-06, -4.444444444444445e-06, -4.444444444444445e-06, -4.444444444444445e-06, -4.444444444444445e-06, -3.3333333333333333e-06, -3.3333333333333333e-06, -3.3333333333333333e-06, -3.3333333333333333e-06, -3.3333333333333333e-06, -2.2222222222222225e-06, -2.2222222222222225e-06, -2.2222222222222225e-06, -2.2222222222222225e-06, -2.2222222222222225e-06, -1.1111111111111112e-06, -1.1111111111111112e-06, -1.1111111111111112e-06, -1.1111111111111112e-06, -1.1111111111111112e-06],
        ),
        tensor_para=dict(
            args=[
                {
                    "ins": ["input"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["tensor1"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
                {
                    "ins": ["tensor2"],
                    "shape": [(32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,), (32000, 4096), (4096, 4096), (11008, 4096), (4096, 11008), (4096,)],
                    "dtype": [Dtype.float32],
                    "gen_fn": Genfunc.randn,
                },
            ],
        ),
    ),

}
